{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\arttu\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (19.1.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (2.8)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (0.2.0)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (5.2.0)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (4.5.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (1.22.0)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: Twisted>=17.9.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from scrapy) (21.2.0)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from pyOpenSSL>=16.2.0->scrapy) (1.14.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (45.2.0.post20200210)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (19.3.0)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: incremental>=16.10.1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: twisted-iocpsupport~=1.0.0; platform_system == \"Windows\" in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (1.0.1)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from Twisted>=17.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.19)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\arttu\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=17.9.0->scrapy) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arttu\\Documents\\TTY\\Johdanto datatieteisiin\\JoDa\\amazon_scraper.py already exists\n"
     ]
    }
   ],
   "source": [
    "!scrapy genspider amazon_scraper amazon.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import scrapy\n",
    "\n",
    "class AmazonScraperSpider(scrapy.Spider):\n",
    "    name = 'amazon_scraper'\n",
    "    allowed_domains = ['amazon.com']\n",
    "    # assing a product-review-page url below\n",
    "    start_urls = ['https://www.amazon.com/Quality-Durables-Unisex-Washable-Reusable/product-reviews/B088SHJZTK/ref=cm_cr_arp_d_paging_btm_next_2?ie=UTF8&reviewerType=all_reviews&pageNumber=2']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        review_texts = response.css('.a-size-base.review-text')\n",
    "        for i in range(len(review_texts)):\n",
    "            review_texts[i] = \"\".join(review_texts[i].css('::text').extract()).strip()\n",
    "\n",
    "        review_ratings = response.css('[data-hook=\"review-star-rating\"] > span::text').extract()\n",
    "\n",
    "        for i in range(len(review_texts)):\n",
    "            review = {\n",
    "                'text' : review_texts[i],\n",
    "                'rating': review_ratings[i]\n",
    "            }\n",
    "            yield review\n",
    "\n",
    "        next_page_url = response.css('.a-last > a::attr(href)').extract_first()\n",
    "        yield response.follow(next_page_url, self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!scrapy runspider amazon_scraper.py -o out.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
